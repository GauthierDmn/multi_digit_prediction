{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Multi Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get familiar with the multi digit classification task, I first worked on classifying sequences of MNIST numbers. The MNIST dataset is often used as a toy dataset: the images it contains are rather centered and without much noise, which makes the classification much more easier than using real images.\n",
    "\n",
    "In a second notebook I tackled the same problem on the much noiser Street View House Number dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creation of the multi-digit number MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part I used MNIST images to create a new dataset consisting on images of size 28x140 representing multi-digit numbers of length up to 5. To do so, I picked random images from the MNIST dataset and concatenated them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import tarfile\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first extract the MNIST dataset from the Tensorflow tutorial's datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a dataset of 55 000 28x150 images concatenating MNIST images. Each image contains a number between 0 and 99999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empty = np.zeros((28, 28), dtype = np.float32)\n",
    "empty_label = np.eye(11)[10,:]\n",
    "possible_elements = [5, 4, 3, 2, 1]\n",
    "\n",
    "concatenated_images = []\n",
    "concatenated_labels = []\n",
    "concatenated_lengths = []\n",
    "total_elements = 0\n",
    "elements_count = -1\n",
    "while(total_elements != 55000):\n",
    "    labels_added = 1\n",
    "    elements_count = (elements_count + 1)%5\n",
    "    no_elements = possible_elements[elements_count]\n",
    "    \n",
    "    if(total_elements>54995 and total_elements + no_elements > 55000):\n",
    "        break\n",
    "    batch = mnist.train.next_batch(no_elements)\n",
    "    image = np.split(batch[0][0], 28)\n",
    "    label = [np.append(batch[1][0],0.)]\n",
    "    for digit in range(1, no_elements):\n",
    "        image = np.hstack((image, np.split(batch[0][digit], 28)))\n",
    "        label.append(np.append(batch[1][digit],0.).tolist())\n",
    "        labels_added += 1\n",
    "    for digit in range(5-no_elements):\n",
    "        image = np.hstack((image, empty))\n",
    "        label.append(empty_label)\n",
    "        \n",
    "    length = np.zeros(5)\n",
    "    length[labels_added-1] = 1.0\n",
    "    \n",
    "    concatenated_images.append(image)\n",
    "    concatenated_labels.append(label)\n",
    "    concatenated_lengths.append(length)\n",
    "    total_elements += no_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x142417c50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1039ed400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# An example of created image\n",
    "plt.imshow(concatenated_images[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the images, labels and length in pickle files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_images_filename = 'images.pickle'\n",
    "set_labels_filename = 'labels.pickle'\n",
    "set_lengths_filename = 'lengths.pickle'\n",
    "def maybe_pickle(set_filename, data):\n",
    "    try:\n",
    "        with open(set_filename, 'wb') as f:\n",
    "            pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', set_filename, ':', e)\n",
    "\n",
    "maybe_pickle(set_images_filename, concatenated_images)\n",
    "maybe_pickle(set_labels_filename, concatenated_labels)\n",
    "maybe_pickle(set_lengths_filename, concatenated_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we first load the data, split it into train and test datasets, and finally reformat it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = ['images.pickle', 'labels.pickle', 'lengths.pickle']\n",
    "\n",
    "with open(pickle_file[0], 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "with open(pickle_file[1], 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "with open(pickle_file[2], 'rb') as f:\n",
    "    lengths = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (16498, 28, 140) (16498, 5, 11) (16498, 5)\n",
      "Test set (1834, 28, 140) (1834, 5, 11) (1834, 5)\n"
     ]
    }
   ],
   "source": [
    "# We take 90% of the data for training and 10% for testing\n",
    "split = int(len(dataset)*0.9)\n",
    "\n",
    "train_dataset = np.asarray(dataset[:split]) \n",
    "test_dataset = np.asarray(dataset[split:])\n",
    "train_labels = np.squeeze(np.asarray(labels[:split])) \n",
    "test_labels = np.squeeze(np.asarray(labels[split:]))\n",
    "train_lengths = np.asarray(lengths)[:split,:]\n",
    "test_lengths = np.asarray(lengths)[split:,:]\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape, train_lengths.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape, test_lengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (16498, 28, 140, 1) (16498, 5, 11) (16498, 5)\n",
      "Test set (1834, 28, 140, 1) (1834, 5, 11) (1834, 5)\n"
     ]
    }
   ],
   "source": [
    "#We add the unique channel as a 4th dimension\n",
    "\n",
    "image_size = 28\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "def reformat_dataset(dataset):\n",
    "    dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size*5, num_channels)).astype(np.float32)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = reformat_dataset(train_dataset)\n",
    "test_dataset = reformat_dataset(test_dataset)\n",
    "print('Training set', train_dataset.shape, train_labels.shape, train_lengths.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape, test_lengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x142773208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxP8DBmlQLr42FVwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1424247f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[126,:,:,:].reshape((28,140)), cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train a Deep CNN to classify these images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth = 64\n",
    "num_hidden = 128\n",
    "image_size = 28\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size*5, num_channels))\n",
    "    tf_train_lengths = tf.placeholder(tf.float32, shape=(batch_size, 5))\n",
    "    tf_train_labels1 = tf.placeholder(tf.float32, shape=(batch_size, 11))\n",
    "    tf_train_labels2 = tf.placeholder(tf.float32, shape=(batch_size, 11))\n",
    "    tf_train_labels3 = tf.placeholder(tf.float32, shape=(batch_size, 11))\n",
    "    tf_train_labels4 = tf.placeholder(tf.float32, shape=(batch_size, 11))\n",
    "    tf_train_labels5 = tf.placeholder(tf.float32, shape=(batch_size, 11))\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "    # Variables.\n",
    "    layer1_weights = tf.get_variable('layer1',\n",
    "      [patch_size, patch_size, num_channels, depth], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "    layer2_weights = tf.get_variable('layer2',\n",
    "      [patch_size, patch_size, depth, depth], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "    layer3_weights = tf.get_variable('layer3',\n",
    "      [1152, num_hidden], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    layer4_weights = tf.get_variable('layer4',\n",
    "      [num_hidden, 5], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer4_biases = tf.Variable(tf.constant(1.0, shape=[5]))\n",
    "    layer5_weights = tf.get_variable('layer5',\n",
    "      [num_hidden, 11], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer5_biases = tf.Variable(tf.constant(1.0, shape=[11]))\n",
    "    layer6_weights = tf.get_variable('layer6',\n",
    "      [num_hidden, 11], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer6_biases = tf.Variable(tf.constant(1.0, shape=[11]))\n",
    "    layer7_weights = tf.get_variable('layer7',\n",
    "      [num_hidden, 11], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer7_biases = tf.Variable(tf.constant(1.0, shape=[11]))\n",
    "    layer8_weights = tf.get_variable('layer8',\n",
    "      [num_hidden, 11], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer8_biases = tf.Variable(tf.constant(1.0, shape=[11]))\n",
    "    layer9_weights = tf.get_variable('layer9',\n",
    "      [num_hidden, 11], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer9_biases = tf.Variable(tf.constant(1.0, shape=[11]))\n",
    "  \n",
    "    # Model.\n",
    "    def model(data, layer_weights, layer_biases):\n",
    "        \n",
    "        conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer1_biases)\n",
    "        pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "        \n",
    "        conv = tf.nn.conv2d(pool, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(conv + layer2_biases)\n",
    "        pool = tf.nn.max_pool(hidden, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')\n",
    "        \n",
    "        shape = pool.get_shape().as_list()\n",
    "        reshape = tf.reshape(pool, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "        \n",
    "        return tf.matmul(hidden, layer_weights) + layer_biases\n",
    "  \n",
    "    # Training computation.\n",
    "    logits1 = model(tf_train_dataset, layer4_weights, layer4_biases)\n",
    "    loss1 = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_lengths, logits=logits1))\n",
    "    \n",
    "    logits2 = model(tf_train_dataset, layer5_weights, layer5_biases)\n",
    "    loss2 = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels1, logits=logits2))\n",
    "    \n",
    "    logits3 = model(tf_train_dataset, layer6_weights, layer6_biases)\n",
    "    loss3 = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels2, logits=logits3))\n",
    "    \n",
    "    logits4 = model(tf_train_dataset, layer7_weights, layer7_biases)\n",
    "    loss4 = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels3, logits=logits4))\n",
    "    \n",
    "    logits5 = model(tf_train_dataset, layer8_weights, layer8_biases)\n",
    "    loss5 = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels4, logits=logits5))\n",
    "    \n",
    "    logits6 = model(tf_train_dataset, layer9_weights, layer9_biases)\n",
    "    loss6 = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels5, logits=logits6))\n",
    "    \n",
    "    loss = loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n",
    "    \n",
    "    # Optimizer.    \n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.04, global_step, 10000, 0.95)\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction1 = tf.nn.softmax(logits1)\n",
    "    train_prediction2 = tf.nn.softmax(logits2)\n",
    "    train_prediction3 = tf.nn.softmax(logits3)\n",
    "    train_prediction4 = tf.nn.softmax(logits4)\n",
    "    train_prediction5 = tf.nn.softmax(logits5)\n",
    "    train_prediction6 = tf.nn.softmax(logits6)\n",
    "\n",
    "    test_prediction1 = tf.nn.softmax(model(tf_test_dataset, layer4_weights, layer4_biases))\n",
    "    test_prediction2 = tf.nn.softmax(model(tf_test_dataset, layer5_weights, layer5_biases))\n",
    "    test_prediction3 = tf.nn.softmax(model(tf_test_dataset, layer6_weights, layer6_biases))\n",
    "    test_prediction4 = tf.nn.softmax(model(tf_test_dataset, layer7_weights, layer7_biases))\n",
    "    test_prediction5 = tf.nn.softmax(model(tf_test_dataset, layer8_weights, layer8_biases))\n",
    "    test_prediction6 = tf.nn.softmax(model(tf_test_dataset, layer9_weights, layer9_biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 27.998272\n",
      "Minibatch accuracy: 9.1%\n",
      "Test accuracy: 36.4%\n",
      "Minibatch loss at step 50: 6.970283\n",
      "Minibatch accuracy: 57.0%\n",
      "Minibatch loss at step 100: 6.439221\n",
      "Minibatch accuracy: 61.2%\n",
      "Minibatch loss at step 150: 5.515904\n",
      "Minibatch accuracy: 67.7%\n",
      "Minibatch loss at step 200: 4.800478\n",
      "Minibatch accuracy: 72.7%\n",
      "Minibatch loss at step 250: 4.353178\n",
      "Minibatch accuracy: 73.7%\n",
      "Minibatch loss at step 300: 2.828442\n",
      "Minibatch accuracy: 85.2%\n",
      "Minibatch loss at step 350: 2.375288\n",
      "Minibatch accuracy: 85.7%\n",
      "Minibatch loss at step 400: 2.069396\n",
      "Minibatch accuracy: 88.0%\n",
      "Minibatch loss at step 450: 2.159977\n",
      "Minibatch accuracy: 86.5%\n",
      "Minibatch loss at step 500: 1.529115\n",
      "Minibatch accuracy: 90.4%\n",
      "Test accuracy: 90.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 501\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_lengths = train_lengths[offset:(offset + batch_size), :]\n",
    "        batch_labels1 = train_labels[offset:(offset + batch_size), 0, :]\n",
    "        batch_labels2 = train_labels[offset:(offset + batch_size), 1, :]\n",
    "        batch_labels3 = train_labels[offset:(offset + batch_size), 2, :]\n",
    "        batch_labels4 = train_labels[offset:(offset + batch_size), 3, :]\n",
    "        batch_labels5 = train_labels[offset:(offset + batch_size), 4, :]\n",
    "\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_lengths : batch_lengths, tf_train_labels1 : batch_labels1,\n",
    "                     tf_train_labels2 : batch_labels2, tf_train_labels3 : batch_labels3, \n",
    "                     tf_train_labels4 : batch_labels4, tf_train_labels5 : batch_labels5,\n",
    "                    }\n",
    "        _, l, predictions1, predictions2, predictions3, predictions4, predictions5, predictions6 = session.run(\n",
    "      [optimizer, loss, train_prediction1, train_prediction2, train_prediction3, train_prediction4,\n",
    "      train_prediction5, train_prediction6], feed_dict=feed_dict)\n",
    "        if (step % 50 == 0):\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%'% ((accuracy(predictions1,batch_lengths) +\n",
    "                                                     accuracy(predictions2,batch_labels1) +\n",
    "                                                     accuracy(predictions3,batch_labels2) +\n",
    "                                                     accuracy(predictions4,batch_labels3) +\n",
    "                                                     accuracy(predictions5,batch_labels4) +\n",
    "                                                     accuracy(predictions6,batch_labels5))/6))\n",
    "        if (step % 500 == 0):\n",
    "            print('Test accuracy: %.1f%%' % ((accuracy(test_prediction1.eval(), test_lengths) +\n",
    "                                             accuracy(test_prediction2.eval(), test_labels[:,0,:]) +\n",
    "                                             accuracy(test_prediction3.eval(), test_labels[:,1,:]) +\n",
    "                                             accuracy(test_prediction4.eval(), test_labels[:,2,:]) +\n",
    "                                             accuracy(test_prediction5.eval(), test_labels[:,3,:]) +\n",
    "                                             accuracy(test_prediction6.eval(), test_labels[:,4,:]))/6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We easily obtain a very good accuracy score after a couple of iterations."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
